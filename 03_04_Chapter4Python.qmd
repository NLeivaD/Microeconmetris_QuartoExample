---
title: "Chapter 4"
bibliography: references.bib
---

# Code Call Outs

## Code Call Out 4.1: Wild cluster bootstrap implementation

To see the difference between the wild cluster bootstrap described in Section 4.2.3.2 of the book and other clustering options such as standard cluster bootstrap or clustered standard errors we will set up an example by hand of the wild cluster bootstrap.  We will do this with data provided by @PorterSerra2020 who conducted a field experiment which sought to test whether student exposure to engaging and successful women instructors in early economics classes increases the likelihood that female students go on to major in economics.  The dataset is provided under the name `PorterSerra2020.csv`, and we will open this data as `data` below:

```{python}
import pandas as pd
data = pd.read_csv("Datasets/PorterSerra2020.csv", sep = ";")
```

Following @PorterSerra2020 we will estimate the following linear probability model (LPM)
$$Y_{i} = \beta_0 + \beta_1 dt_i + \beta_2 dT_i + \beta_3 dt_i \times dT_i + \delta \mathbf{X}_i + \varepsilon_i$$
where we use identical notation from their paper.  Treatment was randomly applied at the class level in 2016, and classes also existed in 2015, but no treatment was applied.  Above, $Y_i$ is a student's (binary) decision of whether or not to major in economics (`econmajor`), $dt_i$ (`yr_2016`) a dummy equal to one if she took the class in 2016 and zero if she took a class in 2015, and $dT_i$ (`treatment_class`) is a dummy equal to one if she is in a treatment class, and zero if she is in a control class. The interaction between these two dummies (`treat2016`) is the coefficient of interest and $\mathbf{X}_i$ is a vector of individual, demographic and class controls such as if the course was taught by a female professor (`female_prof`), if the student is an in-state student (`instate`), if the student is in freshman year (`freshman`), if the student is american (`american`), the student's cumulative GPA (`ACumGPA`), the student's grade in their Principles of Economics course (`gradePrinciples`) and if the student take a class with a limit of 40 students (`small_class`).  As treatment is assigned at the class level (`class_fe2`), and as there are few clusters (12 clusters), the authors proceed to conduct inference using a wild cluster bootstrap.  We conduct this procedure below.

Here in particular we are interested in the parameter $\beta_3$ which under difference-in-difference assumptions will identify the effect of female role models on future enrollment in an economics major.  Before examining this process, we will estimate the LPM in order to get an estimate of the coefficient of interest $\widehat{\beta}_3$, along with the (traditional) cluster-robust standard error $se\left(\widehat{\beta}_3\right)$, and resulting $t$-statistic for the test of a null effect: $t=\left(\widehat{\beta}_3 - 0\right)/se\left(\widehat{\beta}_3\right)$.  We will do this using the `Regpyhdfe` function from the `regpyhdfe` package to estimate our regression model. The usage of this function includes a several arguments separate from each other, one for the dependent variable, other for the explanatory covariates, or predictors, other for the clustering variables and other for one of the the variables that determine the fixed effects (or ommitted if no fixed effects are desired). As we are not estimating with fixed effects or IV we don't indicate an `ids` argument:

```{python}
from regpyhdfe import Regpyhdfe
data['Constant'] = 1
LPM = Regpyhdfe(df = data[data['female'] == 1], target = 'econmajor', 
                       predictors = ['yr_2016', 'treatment_class', 'treat2016',
                                     'female_prof', 'instate', 'freshman',
                                     'american', 'ACumGPA', 'gradePrinciples',
                                     'small_class', 'Constant'],
                       cluster_ids=['class_fe2']).fit()
print(LPM.summary2())
```

It can be seen that the coefficient of interest is 0.0801 (as per column 4 of Table 4 of @PorterSerra2020) with a cluster-robust standard error of 0.0365 and a resulting t-statistic of 2.197. Below, we store these values along with the residuals of this unrestricte regression $\widehat{\varepsilon}$:

```{python}
beta3_hat = LPM.params['treat2016']
se_beta3_hat = LPM.bse['treat2016']
t_beta3_hat = LPM.tvalues['treat2016']
eps_hat = LPM.resid
```

Because we are interested in considering the variation of data in a model where we assume the null hypothesis $\beta_3=0$ is true, we will now *impose* this hypothesis, and re-estimate our model.  We do this below, imposing the restriction $\beta_3 = 0$ by simply omiting the `treat2016` variable from the model, storing the restricted residuals from this regression as $\tilde{\varepsilon}$. 

```{python}
LPM_r = Regpyhdfe(df = data[data['female'] == 1], target = 'econmajor',
                  predictors = ['yr_2016', 'treatment_class', 'female_prof', 
                                'instate', 'freshman', 'american', 'ACumGPA', 
                                'gradePrinciples', 'small_class', 'Constant'],
                  cluster_ids=['class_fe2']).fit()
eps_tilde = LPM_r.resid
```

These restricted residuals `eps_tilde` above will be key in our wild cluster bootstrap procedure.  For a given bootstrap replication, for each cluster we will assign a value of -1 or +1, and multiply the previous residuals by this (cluster-specific) value.  This will maintain correlations between residuals fixed within each cluster, but allow correlations to vary between clusters.  We will thus generate a new "sample" of data taking original data and updated residuals, resulting in a new outcome for $Y_i$.

Below we will initialise this wild cluster bootstrap procedure, setting some large amount of bootstrap replicates (here 999), before storing the data we need as `bsample`.  We will then also incorporate the residuals from above into this dataframe, so `bsample` contains all relevant covariates, as well as the restricted residuals.  It is worth noting, that in practice, all we require from these covariates is the ability to form $\widehat{Y}_i=\widehat\beta_0+\widehat\beta_1 dt_i + \widehat\beta_2 dT_i + \widehat\delta \mathbf{X}_i$, and we could actually just work with the quantity $\widehat{Y}_i$ below (you may wish to confirm this to yourself by editing the code below).  However, for ease of exposition we will work with the full set of covariates in code below, even though this is somewhat less efficient.

```{python}
B = 999
WildClusterBootstrap = pd.DataFrame({'beta3': [float('nan')] * B,
                                     'se_beta3': [float('nan')] * B,
                                     't_stat': [float('nan')] * B})
bsample = data[data['female'] == 1][['econmajor', 'yr_2016', 'treatment_class', 
                                     'treat2016', 'female_prof', 'instate', 
                                     'freshman', 'american', 'ACumGPA', 
                                     'gradePrinciples', 'small_class', 
                                     'class_fe2', 'Constant']].reset_index(drop = False)
bsample['eps_tilde'] = eps_tilde
```

Now let's see what each iteration of a wild cluster bootstrap looks like.  As we will generate our new sample of data by (randomly) selecting values of -1 or 1 for each cluster to form "resampled" residuals, we will start by drawing these "Rademacher" weights for each cluster.  Below we do this by first generating a cluster-specific draw for each cluster $g$ which assigns $a_g = 1$ or $a_g = -1$ with probability 0.5 (as seen in `clusters`).  This value $a_g$ is joined into our main data:
```{python}
import random
clusters = pd.DataFrame({'class_fe2': bsample['class_fe2'].unique(),
                         'ag': random.choices([-1, 1], k = 12)})
print(clusters)
bsample = pd.merge(left = bsample, right = clusters, how = 'left',
                   on = 'class_fe2')
```
Now, based on this draw and the original errors from the restricted model, we will generate the new set of bootstrap errors, which below we call `berrors`:
```{python}
bsample['berrors'] = bsample['eps_tilde'] * bsample['ag']
```
Finally, below we will generate our new resampled outcome variable `beconmajor` from covariates, restricted regression estimates, and our resampled error term `berrors`.
```{python}
bsample['beconmajor'] = (LPM_r.params['Constant'] + 
                         LPM_r.params['yr_2016'] * bsample['yr_2016'] +
                         LPM_r.params['treatment_class'] * bsample['treatment_class'] +
                         LPM_r.params['female_prof'] * bsample['female_prof'] +
                         LPM_r.params['instate'] * bsample['instate'] +
                         LPM_r.params['freshman'] * bsample['freshman'] +
                         LPM_r.params['american'] * bsample['american'] +
                         LPM_r.params['ACumGPA'] * bsample['ACumGPA'] +
                         LPM_r.params['gradePrinciples'] * bsample['gradePrinciples'] +
                         LPM_r.params['small_class'] * bsample['small_class'] +
                         bsample['berrors'])
```

With this data in hand, we estimate the non-restricted model exactly as we did so previously with `Regpyhdfe`.  Below, we estimate this model, and examine summary output:

```{python}
LPM_b = Regpyhdfe(df = bsample, target = 'beconmajor',
                  predictors = ['yr_2016', 'treatment_class', 'female_prof', 
                                'instate', 'freshman', 'american', 'ACumGPA', 
                                'gradePrinciples', 'small_class', 'Constant',
                                'treat2016'],
                  cluster_ids = ['class_fe2']).fit()
print(LPM_b.summary2())
```

You will note here that the coefficient of interest (that on `treat2016`) is small and insignificant.  This should not be surprising to us, as we have imposed that this coefficient should be zero in the process where we generated `beconmajor` previously.  The idea of this process is that in this way we should have some idea of the variation we may expect in parameter estimates when the true parameter actually *is* zero.  If we observe that our true estimate greatly exceeds these "null" estimates, we may be willing to conclude that the original effect is real.  We store the relevant values from our regression model below to calculate a t-statistic from this bootstrap replicate.

```{python}
WildClusterBootstrap['beta3'][0] = LPM_b.params['treat2016']
WildClusterBootstrap['se_beta3'][0] = LPM_b.bse['treat2016']
WildClusterBootstrap['t_stat'][0] = LPM_b.tvalues['treat2016']
```
We wish to see how extreme our original t-statistic is compared to many t-statistics generated in this way, where the null is imposed.  Thus, we will now repeat the previous bootstrap replicate $B-1$ more times in a loop, so that we have $B$ t-statistics.

```{python}
for b in range(1,B):
  # Erase from common data frame the data of previous replication
  bsample = bsample.drop(columns = ['ag', 'berrors', 'beconmajor'])
  # Add new replication data
  clusters = pd.DataFrame({'class_fe2': bsample['class_fe2'].unique(),
                             'ag': random.choices([-1, 1], k = 12)})
  bsample = pd.merge(left = bsample, right = clusters, how = 'left',
                       on = 'class_fe2')
  bsample['berrors'] = bsample['eps_tilde'] * bsample['ag']
  bsample['beconmajor'] = (LPM_r.params['Constant'] + 
                             LPM_r.params['yr_2016'] * bsample['yr_2016'] +
                             LPM_r.params['treatment_class'] * bsample['treatment_class'] +
                             LPM_r.params['female_prof'] * bsample['female_prof'] +
                             LPM_r.params['instate'] * bsample['instate'] +
                             LPM_r.params['freshman'] * bsample['freshman'] +
                             LPM_r.params['american'] * bsample['american'] +
                             LPM_r.params['ACumGPA'] * bsample['ACumGPA'] +
                             LPM_r.params['gradePrinciples'] * bsample['gradePrinciples'] +
                             LPM_r.params['small_class'] * bsample['small_class'] +
                             bsample['berrors'])
  # Estimate artificial model
  LPM_b = Regpyhdfe(df = bsample, target = 'beconmajor',
                      predictors = ['yr_2016', 'treatment_class', 'female_prof', 
                                    'instate', 'freshman', 'american', 'ACumGPA', 
                                    'gradePrinciples', 'small_class', 'Constant',
                                    'treat2016'],
                      cluster_ids = ['class_fe2']).fit()
  # Store values
  WildClusterBootstrap['beta3'][b] = LPM_b.params['treat2016']
  WildClusterBootstrap['se_beta3'][b] = LPM_b.bse['treat2016']
  WildClusterBootstrap['t_stat'][b] = LPM_b.tvalues['treat2016']
```

We can see below what this "null distribution" of t-statistics looks like.  It is not a surprise that these are centred around 0, because this is what our model has imposed.  However, more interesting than this is to see they type of variation in t-statistics which we can expect in our data with null effects imposed.  We can see, below, that this looks somewhat heavier-tailed than a standard t-distribution.

```{python}
WildClusterBootstrap.plot(kind = 'hist', column = 't_stat', bins = 20,
                          title = '', legend = '', ylabel = '',
                          xlabel = 'Bootstrap t-statistics')
```

From this distribution we can calculate a p-value by asking what proportion of t-statistics from the null distribution exceed our estimated t-statistic from the unrestricted model.  We do this below, observing that the p-value is quite close to that reported in @PorterSerra2020 (who report a p-value of 0.089), only differing due to random variation in draws of the Rademacher weights.


<!--
Now we compare our original $t$-statistic `r round(t_beta3_hat, 3)` with the 97.5 percentile of the $t$-statistics computed in our bootstraping to see if we can reject the null of $\beta_3 = 0$ to a 5% significance level

```{r}
t97_5 <- quantile(WildClusterBootstrap$t_stat, 0.975)
if(abs(t_beta3_hat) > abs(t97_5)){
  print("The null is rejected.")
} else {
  print("We can't reject the null.")
}
```
-->

```{python}
pval = (abs(WildClusterBootstrap['t_stat']) > abs(t_beta3_hat)).mean()
print('The p-value is: ', round(pval, 3))
```

We also could repeat this exercise with the `wildboottest` function from the `wildboottest` developed by @FischerRoodman2021 and arrive to the same conclusion.  This function works with the original model we estimated previously (`LPM`), and conducts an identical procedure to that which we have done above "by hand".  Any difference in p-values is incidental, owing to different random draws.  

```{python}
import statsmodels.formula.api as sm
model = sm.ols(data = data[data['female'] == 1].reset_index(), 
               formula = 'econmajor ~ yr_2016 + treatment_class + treat2016' +
               ' + female_prof + instate + freshman + american + ACumGPA +' +
               ' gradePrinciples + small_class')
from wildboottest.wildboottest import wildboottest
boot = wildboottest(model, param = 'treat2016', B = 999,
                     cluster = data[data['female'] == 1].reset_index().class_fe2)
print('The p-value with the user-written function is: ' +
      str(round(boot['p-value'].iloc[0], 3)))
```

In principle, using such a library is likely the preferred way of conducting procedures such as the wild cluster bootstrap, however it is illustrative to see how it works in practice, as we do above.  Although other feautres such as confidence intervals formed by inverting the test and iteratively searching for bounds are not available yet.

<!--
nice element of user-written procedures such as that of @Roodmanetal2019 is that it also seamlessly returns other quantities of interest which we would have to generate ourselves above, such as confidence interval, which we can see below:

```{r}
paste0("The confidence interval is: [", 
       round(boot$conf_int[1], 3),
       ",", round(boot$conf_int[2], 3), "].")
```
These values correspond closely to the original 95% CIs reported in the paper of [-0.015; 0.160].
-->

** Update up to here, not found yet a user-written package for "normal" cluster bootstrap**
Finally as a comparative exercise we may be interested in seeing how this procedure compares to a standard clustered bootstrap.  While there are many ways we could do this -- including quite easily by hand -- we examine this below using the `ClusterBootstrap` library.  It turns out that while the 95% CI on `treat2016` coming from clustered bootstrap is narrower than the 95% CI from the wild cluster bootstrap (as expected), the difference is not *so* substantial in this particular case. 

```{r}
library(ClusterBootstrap)
set.seed(121316)
boot2 <- clusbootglm(model = econmajor ~ yr_2016 + treatment_class +
                     treat2016 + female_prof + instate + freshman +
                     american + ACumGPA + gradePrinciples +
                     small_class, data = data[data$female == 1,],
                     clusterid = class_fe2,
                     B = 1000)
boot2$percentile.interval
```

## Code Call Out 4.2: Exploring the Two-way Fixed Effect Model and Parameter Decomposition

**Two-Way Fixed Effects Estimators and Heterogeneous Treatment Effects** To understand the potential issues related to heterogeneous treatment effects over time and two-way fixed effect estimators, we will examine a pair of numerical examples. In particular, we will focus on the composition of the two way FE estimator $\tau$ estimated from: $$
y_{st} = \gamma_s + \lambda_t + \tau w_{st} + \varepsilon_{st}
$$ {#eq-twfe} where $y_{st}$ is the outcome variable, $\gamma_s$ and $\lambda_t$ are state (unit) and time fixed effects, $w_{st}$ is the binary treatment variable that takes the value of 1 if a state (unit) $s$ is treated at time $t$ and otherwise takes 0. We will work with a quite tractable example based on three units and 10 time periods, and will document how the approaches taken by @GoodmanBacon2018 and by @deChaisemartinDhaultfoeuille2019 to understand the two-way FE estimator compare.

The results from @GoodmanBacon2018 and those from @deChaisemartinDhaultfoeuille2019 are similar, however they take quite different paths to get there. Goodman-Bacon's (like that laid out in @AtheyImbens2018) is "mechanical" in that it is based on the underlying difference-in-differences comparisons between all groups. The result in @deChaisemartinDhaultfoeuille2019 is based on a potential outcomes frame-work, and counterfactuals under parallel trend assumptions. Thus to examine how these methods work requires somewhat different frameworks. In the case of @GoodmanBacon2018, we should consider all possible DD comparisons, while in the case of @deChaisemartinDhaultfoeuille2019 we should consider the treatment effect for each unit and time period, which requires knowing the observed and counterfactual state. While the approaches the two papers take to understand the content of the estimator differ, they refer to the same estimator, so always recover the same parameter estimate. To examine this in a more applied way, we will look at a simulated example.

To do this, let's consider a panel of 3 states/areas over the 10 years ($t$) of 2000 to 2009. One of these units is entirely untreated ($unit = 1$ or group $U$), one is treated at an early time period, 2003, ($unit = 2$ or group $k$), and the other is treated at a later time period, 2006, ($unit = 3$ or group $l$). We will construct a general structure for this data below:

```{python}
import pandas as pd
import numpy as np

Data = pd.DataFrame({'unit': np.ceil(np.arange(1,31)/10), 
                     'year': np.tile(np.arange(2000, 2010), 3)})
Data.head()
```

We will consider a simple-case where the actual data-generating process is known as: $$y_{unit,t} = 2 + 0.2 \times (t - 2000) + 1 \times unit + \beta_1 \times post \times unit + \beta_2 \times post \times unit \times (t - treat).$$ Here $unit$ refers to the unit number listed above (1, 2 or 3), $post$ indicates that a unit is receiving treatment in the relevant time period $t$, and $treat$ refers to the treatment period (2003 for unit 2, and 2006 for unit 3). Let's generate treatment, time to treatment, and post-treatment variables in `R`:

```{python}
Data['treat'] = np.where(Data['unit'] == 2, 2006, 
                         np.where(Data['unit'] == 3, 2003, 0))
Data['time'] = np.where(Data['treat'] == 0, 0, Data['year'] - Data['treat'])
Data['post'] = np.where(((Data['time'] >= 0) & (Data['treat'] != 0)), 1, 0) 
```

This specification allows for each unit to have its own fixed effect, given that $unit$ is multiplied by 1, and allows for a general time trend increasing by 0.2 units each period across the whole sample. These parameters are not so important, as what we care about are the treatment effects themselves. The impact of treatment comes from the units $\beta_1$ and $\beta_2$. The first of these, $\beta_1$, captures an immediate unit-specific jump when treatment is implemented which remains stable over time. The second of these, $\beta_2$, implies a trend break occurring *only* for the treated units once treatment comes into place. We will consider 2 cases below. In the first case $\beta_1 = 1$ and $\beta_2 = 0$ (a simple case with a constant treatment effect per unit):

```{python}
Data['y1'] = 2 + (Data['year'] - 2000) * 0.2 + 1 * Data['unit'] + 1 * Data['post'] * Data['unit'] + 0 * Data['post'] * Data['unit'] * (Data['time'])
```

and in a second case $\beta_1 = 1$ and $\beta_2 = 0.45$. This is a more complex case in which there are heterogeneous treatment effects over time:

```{python}
Data['y2'] = 2 + (Data['year'] - 2000) * 0.2 + 1 * Data['unit'] + 1 * Data['post'] * Data['unit'] + 0.45 * Data['post'] * Data['unit'] * (Data['time'])
```

These two cases are plotted next where the line with empty circles refers to group $U$, the line with black filled circles refers to group $k$ and the line with squares refers to group $l$

```{python fig.width=10}
#| code-fold: true
#| code-summary: "Show the plot code"
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_theme()
[Fig1, ax] = plt.subplots(1,2)
PanelA = sns.lineplot(data=Data[Data['unit'] == 1], x ='year', y='y1',
                      color='black', size=1, ax = ax[0]) 
PanelA = sns.scatterplot(data=Data[Data['unit'] == 1], x ='year', y='y1',
                      color='black', marker="$\circ$", ax = ax[0])
PanelA = sns.lineplot(data=Data[Data['unit'] == 2], x ='year', y='y1',
                      color='black', size=1, ax = ax[0])
PanelA = sns.scatterplot(data=Data[Data['unit'] == 2], x ='year', y='y1',
                      color='black', ax = ax[0])
PanelA = sns.lineplot(data=Data[Data['unit'] == 3], x ='year', y='y1',
                      color='black', size=1, ax = ax[0])
PanelA = sns.scatterplot(data=Data[Data['unit'] == 3], x ='year', y='y1',
                      color='black', marker='s', ax = ax[0])
PanelA.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelA.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelA.set_yticks([0, 2, 4, 6, 8, 10, 12])
PanelA.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelA.legend([],[], frameon=False)
PanelA.set_ylabel('Outcome Variable')
PanelA.set_xlabel('Time')
PanelA.set_title('(a) Simple Decomposition')
PanelB = sns.lineplot(data=Data[Data['unit'] == 1], x ='year', y='y2',
                      color='black', size=1, ax = ax[1])
PanelB = sns.scatterplot(data=Data[Data['unit'] == 1], x ='year', y='y2',
                      color='black', marker="$\circ$", ax = ax[1])
PanelB = sns.lineplot(data=Data[Data['unit'] == 2], x ='year', y='y2',
                      color='black', size=1, ax = ax[1])
PanelB = sns.scatterplot(data=Data[Data['unit'] == 2], x ='year', y='y2',
                      color='black', ax = ax[1])
PanelB = sns.lineplot(data=Data[Data['unit'] == 3], x ='year', y='y2',
                      color='black', size=1, ax = ax[1])
PanelB = sns.scatterplot(data=Data[Data['unit'] == 3], x ='year', y='y2',
                      color='black', marker='s', ax = ax[1])
PanelB.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelB.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelB.set_yticks([0, 5, 10, 15, 20])
PanelB.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelB.legend([],[], frameon=False)
PanelB.set_ylabel('Outcome Variable')
PanelB.set_xlabel('Time')
PanelB.set_title('(b) Decomposition with trends')
```

### The Two-way Fixed Effect Estimator

First we will estimate the parameter by two-way fixed effects regression. This will provide us with the parameter estimate that both @GoodmanBacon2018 and @deChaisemartinDhaultfoeuille2019 will construct in a piece-wise fashion. This is done relatively simply in `R`. We simply estimate @eq-twfe by linear regression using `lm` as laid out below:

```{python}
import statsmodels.api as sm

case1 = sm.OLS.from_formula('y1 ~ post + C(unit) + C(year)', data=Data).fit()
print("The parameter estimates by two-way fixed effects regression for the case 1 is: ", case1.params["post"])
case2 = sm.OLS.from_formula('y2 ~ post + C(unit) + C(year)', data=Data).fit()
print("The parameter estimates by two-way fixed effects regression for the case 2 is: ", case2.params["post"])
```

Here we see that the coefficient of interest is 2.454545. We can see that this is between the two unit-specific jumps that occur with treatment (2 and 3). We will see below why it takes this particular weighted average.

### @GoodmanBacon2018 Decomposition

Using the values simulated above, let's see how the @GoodmanBacon2018 decomposition allows us to understand estimated treatment effects. We will consider both:\
- (a) Simple Decomposition\
- (b) Decomposition with trends

The methodology @GoodmanBacon2018 decomposition suggests that we should calculate all $2 \times 2$ combinations of states and time where post-treatment units are compared to "untreated" unit (laid out at more length in the boo). In this example, this provides four specific effects, which contribute to $\widehat{\tau}$ as a weighted mean. The specific effects desired are:

-   A. $\widehat{\beta}^{2\times2}_{kU}$ from the comparison of the early treated unit with the untreated unit.\
-   B. $\widehat{\beta}^{2\times2}_{lU}$, from the comparison of the latter treated unit with the untreated unit.\
-   C. $\widehat{\beta}^{2\times2,k}_{kl}$, from the comparison of the early and latter treated units, when the early unit begin to be treated.\
-   D. $\widehat{\beta}^{2\times2,l}_{kl}$, from the comparison of the early and latter treated units, when the latter unit begin to be treated.

These will then be weighted as laid out in @GoodmanBacon2018 to provide the regression-based estimate.

#### (a) Simple Decomposition

In this case the @GoodmanBacon2018 methodology estimate $\widehat{\tau}$ weighting the next four DD comparisons

```{python}
#| code-fold: true
#| code-summary: "Show the plot code"
[Fig2, ax] = plt.subplots(2,2)
### PanelA
PanelA = sns.lineplot(data=Data[Data['unit'] == 1], x ='year', y='y1',
                      color='black', size=1, ax = ax[0,0]) 
PanelA = sns.scatterplot(data=Data[Data['unit'] == 1], x ='year', y='y1',
                      color='black', marker="$\circ$", ax = ax[0,0])
PanelA = sns.lineplot(data=Data[Data['unit'] == 2], x ='year', y='y1',
                      color='black', size=1, ax = ax[0,0], alpha = 0.1)
PanelA = sns.scatterplot(data=Data[Data['unit'] == 2], x ='year', y='y1',
                      color='black', ax = ax[0,0], alpha = 0.1)
PanelA = sns.lineplot(data=Data[Data['unit'] == 3], x ='year', y='y1',
                      color='black', size=1, ax = ax[0,0])
PanelA = sns.scatterplot(data=Data[Data['unit'] == 3], x ='year', y='y1',
                      color='black', marker='s', ax = ax[0,0])
PanelA.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelA.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelA.set_yticks([0, 2, 4, 6, 8, 10, 12])
PanelA.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelA.legend([],[], frameon=False)
PanelA.set_ylabel('Outcome Variable')
PanelA.set_xlabel('Time')
PanelA.set_title('A. Early Group v/s Untreated Group')
### PanelB
PanelB = sns.lineplot(data=Data[Data['unit'] == 1], x ='year', y='y1',
                      color='black', size=1, ax = ax[0,1])
PanelB = sns.scatterplot(data=Data[Data['unit'] == 1], x ='year', y='y1',
                      color='black', marker="$\circ$", ax = ax[0,1])
PanelB = sns.lineplot(data=Data[Data['unit'] == 2], x ='year', y='y1',
                      color='black', size=1, ax = ax[0,1])
PanelB = sns.scatterplot(data=Data[Data['unit'] == 2], x ='year', y='y1',
                      color='black', ax = ax[0,1])
PanelB = sns.lineplot(data=Data[Data['unit'] == 3], x ='year', y='y1',
                      color='black', size=1, ax = ax[0,1], alpha = 0.1)
PanelB = sns.scatterplot(data=Data[Data['unit'] == 3], x ='year', y='y1',
                      color='black', marker='s', ax = ax[0,1], alpha = 0.1)
PanelB.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelB.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelB.set_yticks([0, 2, 4, 6, 8, 10, 12])
PanelB.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelB.legend([],[], frameon=False)
PanelB.set_ylabel('Outcome Variable')
PanelB.set_xlabel('Time')
PanelB.set_title('B. Later Group v/s Untreated Group')
### PanelC
PanelC = sns.lineplot(data=Data[(Data['unit'] == 1) & (Data['year'] < 2006)], 
                      x ='year', y='y1', color='black', size=1, ax = ax[1,0], 
                      alpha = 0.1) 
PanelC = sns.scatterplot(data=Data[(Data['unit'] == 1) & (Data['year'] < 2006)], 
                         x ='year', y='y1', color='black', marker="$\circ$", 
                         ax = ax[1,0], alpha = 0.1)
PanelC = sns.lineplot(data=Data[(Data['unit'] == 2) & (Data['year'] < 2006)], 
                      x ='year', y='y1', color='black', size=1, ax = ax[1,0])
PanelC = sns.scatterplot(data=Data[(Data['unit'] == 2) & (Data['year'] < 2006)], 
                         x ='year', y='y1', color='black', ax = ax[1,0])
PanelC = sns.lineplot(data=Data[(Data['unit'] == 3) & (Data['year'] < 2006)], 
                      x ='year', y='y1', color='black', size=1, ax = ax[1,0])
PanelC = sns.scatterplot(data=Data[(Data['unit'] == 3) & (Data['year'] < 2006)], 
                         x ='year', y='y1', color='black', marker='s', 
                         ax = ax[1,0])
PanelC.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelC.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelC.set_yticks([0, 2, 4, 6, 8, 10, 12])
PanelC.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelC.legend([],[], frameon=False)
PanelC.set_ylabel('Outcome Variable')
PanelC.set_xlabel('Time')
PanelC.set_title('C. Early Group v/s Later Group Before 2006')
### PanelD
PanelD = sns.lineplot(data=Data[(Data['unit'] == 1) & (Data['year'] > 2002)], 
                      x ='year', y='y1', color='black', size=1, ax = ax[1,1], 
                      alpha = 0.1)
PanelD = sns.scatterplot(data=Data[(Data['unit'] == 1) & (Data['year'] > 2002)], 
                         x ='year', y='y1', color='black', marker="$\circ$", 
                         ax = ax[1,1], alpha = 0.1)
PanelD = sns.lineplot(data=Data[(Data['unit'] == 2) & (Data['year'] > 2002)], 
                      x ='year', y='y1', color='black', size=1, ax = ax[1,1])
PanelD = sns.scatterplot(data=Data[(Data['unit'] == 2) & (Data['year'] > 2002)], 
                         x ='year', y='y1', color='black', ax = ax[1,1])
PanelD = sns.lineplot(data=Data[(Data['unit'] == 3) & (Data['year'] > 2002)], 
                      x ='year', y='y1', color='black', size=1, ax = ax[1,1])
PanelD = sns.scatterplot(data=Data[(Data['unit'] == 3) & (Data['year'] > 2002)], 
                         x ='year', y='y1', color='black', marker='s', 
                         ax = ax[1,1])
PanelD.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelD.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelD.set_yticks([0, 2, 4, 6, 8, 10, 12])
PanelD.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelD.legend([],[], frameon=False)
PanelD.set_ylabel('Outcome Variable')
PanelD.set_xlabel('Time')
PanelD.set_title('D. Early Group v/s Later Group After 2003')
```

As seen in the plots, in the simple decomposition these effects are constants of 3 and 2 for early and later treated units given that the "treatment effect" is simply $1 \times unit$ in each case.

##### A. Early Group v/s Untreated Group

In order to calculate the effects we start making the simple DD comparison of the untreated group $U$ ($unit = 1$) with the early treated group $k$ ($unit = 3$) getting $\widehat{\beta}^{2 \times 2}_{kU}$ as $$\widehat{\beta}^{2 \times 2}_{kU} = \left( \overline{y}_k^{Post(k)} - \overline{y}_k^{Pre(k)} \right) - \left( \overline{y}_U^{Post(k)} - \overline{y}_U^{Pre(k)} \right)$$ Where $\overline{y}_k^{Post(k)}$ is the mean of the outcome variable for the early treated group $k$ ($unit = 3$) posterior to treatment, from 2003, $\overline{y}_k^{Pre(k)}$ is the mean for of the outcome variable for the early treated group $U$ ($unit = 3$) prior to treatment, (up until 2002), and $\overline{y}_U^{Post(k)}, \overline{y}_U^{Post(k)}$ are the analogous quantities for the untreated group $U$ ($unit = 1$)

```{python}
((Data[(Data['unit'] == 3) & (Data['post'] == 1)]['y1'].mean() - 
 Data[(Data['unit'] == 3) & (Data['post'] == 0)]['y1'].mean()) -
(Data[(Data['unit'] == 1) & (Data['year'] >= 2003)]['y1'].mean() - 
 Data[(Data['unit'] == 1) & (Data['year'] < 2003)]['y1'].mean()))
```

This result also can be obtained from the linear regression with the canonical DD formula $$y_{unit,t} = \alpha_0 + \alpha_1 \times Post(k) + \alpha_2 \times \mathbf{1}(unit = 3) + \beta_{kU}^{2\times2} \times Post(k) \times \mathbf{1}(unit = 3) + \varepsilon_i$$ Where $Post(k)$ indicates that the year is equal or greater than the year where the group $k$ ($unit = 3$) received the treatment (2003) and $\mathbf{1}(unit = 3)$ indicates if the observation is from the early treated group $k$ ($unit = 3$)

```{python}
Data['post2003'] = np.where(Data['year'] >= 2003, 1, 0)
sm.OLS.from_formula('y1 ~ C(post2003) + C(unit) + C(post2003):C(unit)', 
                    data=Data[Data['unit'] != 2]).fit().summary()
```

A third way to obtain this is from the next linear regression $$y_{unit,t} = \alpha_0 + \beta_{kU}^{2 \times 2} \times Post + \sum_{i = 2001}^{2009} \alpha_{i-2000} \times \mathbf{1}(year = i) + \alpha_{10} \times \mathbf{1}(unit = 3) + \varepsilon_i$$ Where in this case $Post$ indicates if the unit is treated (note for group $U$ this will be always 0), $\mathbf{1}(year = i)$ indicates if the observation is in period $i \in \{2001, \ldots, 2009\}$ and $\mathbf{1}(unit = 3)$ keep its meaning

```{python}
sm.OLS.from_formula('y1 ~ post  + C(year) + C(unit)', 
                    data=Data[Data['unit'] != 2]).fit().summary()
```

Now we store this result for posterior use

```{python}
bku = sm.OLS.from_formula('y1 ~ post  + C(year) + C(unit)', 
                    data=Data[Data['unit'] != 2]).fit().params['post']
```

##### B. Later Group v/s Untreated Group

The next DD comparison we calculate is that which compares the later treated group $l$ ($unit = 2$) with the untreated group $U$ ($unit = 1$), resulting in $\widehat{\beta}^{2 \times 2}_{lU}$. As above, we can generate this DD estimate in a number of ways (most simply by double-differencing with means), and this will then be stored.

```{python}
blu = sm.OLS.from_formula('y1 ~ post  + C(year) + C(unit)', 
                    data=Data[Data['unit'] != 3]).fit().params['post']
print(blu)
print((Data[(Data['unit'] == 2) & (Data['post'] == 1)]['y1'].mean() - 
 Data[(Data['unit'] == 2) & (Data['post'] == 0)]['y1'].mean()) -
(Data[(Data['unit'] == 1) & (Data['year'] >= 2006)]['y1'].mean() - 
 Data[(Data['unit'] == 1) & (Data['year'] < 2006)]['y1'].mean()))
Data['post2006'] = np.where(Data['year'] >= 2006, 1, 0)
sm.OLS.from_formula('y1 ~ C(post2006) + C(unit) + C(post2006):C(unit)', 
                    data=Data[Data['unit'] != 3]).fit().summary()
```

##### C. Early Group v/s Later Group Before 2006

Next we calculate the effects from the DD comparisons of early and later treated groups, up until the later treated group receives treatment (2006). This is: $$\widehat{\beta}^{2 \times 2, k}_{kl} \equiv \left( \overline{y}^{Mid(k,l)}_{k} - \overline{y}^{Pre(k)}_{k} \right) - \left( \overline{y}^{Mid(k,l)}_{l} - \overline{y}^{Pre(k)}_{l} \right)$$ where $\overline{y}^{Mid(k,l)}_{k}$ is the mean of the outcome variable for the early treated group $k$ ($unit = 3$) in the period between the treatment for the group $k$ and the group $l$ ($unit = 2$), from 2003 to 2005, $\overline{y}^{Pre(k)}_{k}$ is the mean for of the outcome variable for the early treated group $k$ ($unit = 3$) previous to treatment, until 2002, and $\overline{y}^{Mid(k,l)}_{l}, \overline{y}^{Pre(k)}_{l}$ are the analogous for the later treated group $l$ ($unit = 2$)

```{python}
bklk = sm.OLS.from_formula('y1 ~ post  + C(year) + C(unit)', 
                    data=Data[(Data['unit'] != 1) & (Data['year'] < 2006)]).fit().params['post']
print(bklk)
print((Data[(Data['unit'] == 3) & ((Data['year'] >= 2003) & (Data['year'] < 2006))]['y1'].mean() - 
 Data[(Data['unit'] == 3) & (Data['year'] < 2003)]['y1'].mean()) -
(Data[(Data['unit'] == 2) & ((Data['year'] >= 2003) & (Data['year'] < 2006))]['y1'].mean() - 
 Data[(Data['unit'] == 2) & (Data['year'] < 2003)]['y1'].mean()))
sm.OLS.from_formula('y1 ~ C(post2003) + C(unit) + C(post2003):C(unit)', 
                    data=Data[(Data['unit'] != 1) & (Data['year'] < 2006)]).fit().summary()
```

##### D. Early Group v/s Later Group After 2003

The last DD comparison is for early and later treated groups, starting from 2006 $$\widehat{\beta}^{2 \times 2, l}_{kl} \equiv \left( \overline{y}^{Post(l)}_{l} - \overline{y}^{Mid(k,l)}_{l} \right) - \left( \overline{y}^{Post(l)}_{k} - \overline{y}^{Mid(k,l)}_{k} \right)$$ Where $\overline{y}^{Post(l)}_{l}$ is the mean of the outcome variable for the later treated group $l$ ($unit = 2$) in the period after this group received the treatment, from 2006, $\overline{y}^{Mid(k,l)}_{l}$ is the mean for of the outcome variable for the later treated group $l$ ($unit = 2$) in the period between the treatment for the group $k$ ($unit = 3$) and the group $l$, from 2003 to 2005, and $\overline{y}^{Post(l)}_{k}, \overline{y}^{Mid(k,l)}_{k}$ are the analogous quantities for the early treated group $k$ ($unit = 3$). We can generate and save this quantity as we have previously:

```{python}
bkll = sm.OLS.from_formula('y1 ~ post  + C(year) + C(unit)', 
                    data=Data[(Data['unit'] != 1) & (Data['year'] > 2002)]).fit().params['post']
print(bkll)
print((Data[(Data['unit'] == 2) & (Data['year'] > 2005)]['y1'].mean() - 
 Data[(Data['unit'] == 2) & ((Data['year'] >= 2003) & (Data['year'] < 2006))]['y1'].mean()) -
(Data[(Data['unit'] == 3) & (Data['year'] > 2005)]['y1'].mean() - 
 Data[(Data['unit'] == 3) & ((Data['year'] >= 2003) & (Data['year'] < 2006))]['y1'].mean()))
sm.OLS.from_formula('y1 ~ C(post2006) + C(unit) + C(post2006):C(unit)', 
                    data=Data[(Data['unit'] != 1) & (Data['year'] > 2002)]).fit().summary()
```

This comparison is the comparison which can potentially result in undesired results if treatment effects are dynamic over time because it views group 3 (the previously treated group) as a control. However, in this case, given that treatment effects are homogenous over time we do not have a major problem here, and we observe that $\widehat{\beta}^{2 \times 2, l}_{kl}=2$.

##### Weights

We can now arrive to the OLS estimate of this two-way fixed effect model by generating the weighted mean of the previous estimates as: $$\widehat{\tau} = W_{kU} \cdot \widehat{\beta}^{2\times 2}_{kU} + W_{lU} \cdot \widehat{\beta}^{2\times 2}_{lU} + W_{kl}^{k} \cdot \widehat{\beta}^{2\times 2,k}_{kl} + W_{kl}^{l} \cdot \widehat{\beta}^{2\times 2,l}_{kl}$$ Where each $W$ is the weight that the respective $\beta$ has in this weighted mean, specifically: \begin{align*} 
W_{kU} & = \frac{(n_k + n_U)^2\widehat{V}^D_{kU}}{\widehat{V}^D} \quad &  \quad W_{lU} & = \frac{(n_l + n_U)^2\widehat{V}^D_{lU}}{\widehat{V}^D} \\ 
W_{kl}^k & = \frac{[(n_k + n_l)(1 - \overline{D}_l)]^2\widehat{V}^{D,k}_{kl}}{\widehat{V}^D} \quad &  \quad W_{kl}^l & = \frac{[(n_k + n_l)(1 - \overline{D}_k)]^2\widehat{V}^{D,l}_{kl}}{\widehat{V}^D}
\end{align*} Where $n$ refers to the sample share of the group

```{python}
nk = 1/3
nl = 1/3
nu = 1/3
```

$\overline{D}$ referes to the share of time the group is treated

```{python}
Dk = Data[Data['unit'] == 3]['post'].mean()
Dl = Data[Data['unit'] == 2]['post'].mean()
```

and $\widehat{V}$ refers to how much treatment varies

```{python}
VkU = 0.5*0.5*(Dk)*(1-Dk)
VlU = 0.5*0.5*(Dl)*(1-Dl) 
Vklk = 0.5*0.5*((Dk-Dl)/(1-Dl))*((1-Dk)/(1-Dl))
Vkll = 0.5*0.5*(Dl/Dk)*((Dk-Dl)/(Dk))
VD   = (sm.OLS.from_formula('post ~ C(unit) + C(year)', 
                           data=Data).fit().resid**2).mean()
```

The weights are thus the following:

```{python}
wkU = (((nk + nu)**2)*VkU)/VD
print(wkU)
wlU = (((nl + nu)**2)*VlU)/VD
print(wlU)
wklk = ((((nk + nl)*(1-Dl))**2)*Vklk)/VD
print(wklk)
wkll = ((((nk + nl)*Dk)**2)*Vkll)/VD
print(wkll)
```

With this in mind the $\tau$ estimate is

```{python}
tau = wkU * bku + wlU * blu + wklk * bklk + wkll * bkll
print(tau)
```

as observed in the two-way fixed effect estimate above.

#### (b) Decomposition with trends

In this case the @GoodmanBacon2018 decomposition follows as above generating the treatment effect as follows:

```{python}
#| code-fold: true
#| code-summary: "Show the plot code"
[Fig3, ax] = plt.subplots(2,2)
### PanelA
PanelA = sns.lineplot(data=Data[Data['unit'] == 1], x ='year', y='y2',
                      color='black', size=1, ax = ax[0,0]) 
PanelA = sns.scatterplot(data=Data[Data['unit'] == 1], x ='year', y='y2',
                      color='black', marker="$\circ$", ax = ax[0,0])
PanelA = sns.lineplot(data=Data[Data['unit'] == 2], x ='year', y='y2',
                      color='black', size=1, ax = ax[0,0], alpha = 0.1)
PanelA = sns.scatterplot(data=Data[Data['unit'] == 2], x ='year', y='y2',
                      color='black', ax = ax[0,0], alpha = 0.1)
PanelA = sns.lineplot(data=Data[Data['unit'] == 3], x ='year', y='y2',
                      color='black', size=1, ax = ax[0,0])
PanelA = sns.scatterplot(data=Data[Data['unit'] == 3], x ='year', y='y2',
                      color='black', marker='s', ax = ax[0,0])
PanelA.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelA.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelA.set_yticks([0, 5, 10, 15, 20])
PanelA.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelA.legend([],[], frameon=False)
PanelA.set_ylabel('Outcome Variable')
PanelA.set_xlabel('Time')
PanelA.set_title('A. Early Group v/s Untreated Group')
### PanelB
PanelB = sns.lineplot(data=Data[Data['unit'] == 1], x ='year', y='y2',
                      color='black', size=1, ax = ax[0,1])
PanelB = sns.scatterplot(data=Data[Data['unit'] == 1], x ='year', y='y2',
                      color='black', marker="$\circ$", ax = ax[0,1])
PanelB = sns.lineplot(data=Data[Data['unit'] == 2], x ='year', y='y2',
                      color='black', size=1, ax = ax[0,1])
PanelB = sns.scatterplot(data=Data[Data['unit'] == 2], x ='year', y='y2',
                      color='black', ax = ax[0,1])
PanelB = sns.lineplot(data=Data[Data['unit'] == 3], x ='year', y='y2',
                      color='black', size=1, ax = ax[0,1], alpha = 0.1)
PanelB = sns.scatterplot(data=Data[Data['unit'] == 3], x ='year', y='y2',
                      color='black', marker='s', ax = ax[0,1], alpha = 0.1)
PanelB.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelB.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelB.set_yticks([0, 5, 10, 15, 20])
PanelB.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelB.legend([],[], frameon=False)
PanelB.set_ylabel('Outcome Variable')
PanelB.set_xlabel('Time')
PanelB.set_title('B. Later Group v/s Untreated Group')
### PanelC
PanelC = sns.lineplot(data=Data[(Data['unit'] == 1) & (Data['year'] < 2006)], 
                      x ='year', y='y2', color='black', size=1, ax = ax[1,0], 
                      alpha = 0.1) 
PanelC = sns.scatterplot(data=Data[(Data['unit'] == 1) & (Data['year'] < 2006)], 
                         x ='year', y='y2', color='black', marker="$\circ$", 
                         ax = ax[1,0], alpha = 0.1)
PanelC = sns.lineplot(data=Data[(Data['unit'] == 2) & (Data['year'] < 2006)], 
                      x ='year', y='y2', color='black', size=1, ax = ax[1,0])
PanelC = sns.scatterplot(data=Data[(Data['unit'] == 2) & (Data['year'] < 2006)], 
                         x ='year', y='y2', color='black', ax = ax[1,0])
PanelC = sns.lineplot(data=Data[(Data['unit'] == 3) & (Data['year'] < 2006)], 
                      x ='year', y='y2', color='black', size=1, ax = ax[1,0])
PanelC = sns.scatterplot(data=Data[(Data['unit'] == 3) & (Data['year'] < 2006)], 
                         x ='year', y='y2', color='black', marker='s', 
                         ax = ax[1,0])
PanelC.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelC.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelC.set_yticks([0, 5, 10, 15, 20])
PanelC.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelC.legend([],[], frameon=False)
PanelC.set_ylabel('Outcome Variable')
PanelC.set_xlabel('Time')
PanelC.set_title('C. Early Group v/s Later Group Before 2006')
### PanelD
PanelD = sns.lineplot(data=Data[(Data['unit'] == 1) & (Data['year'] > 2002)], 
                      x ='year', y='y2', color='black', size=1, ax = ax[1,1], 
                      alpha = 0.1)
PanelD = sns.scatterplot(data=Data[(Data['unit'] == 1) & (Data['year'] > 2002)], 
                         x ='year', y='y2', color='black', marker="$\circ$", 
                         ax = ax[1,1], alpha = 0.1)
PanelD = sns.lineplot(data=Data[(Data['unit'] == 2) & (Data['year'] > 2002)], 
                      x ='year', y='y2', color='black', size=1, ax = ax[1,1])
PanelD = sns.scatterplot(data=Data[(Data['unit'] == 2) & (Data['year'] > 2002)], 
                         x ='year', y='y2', color='black', ax = ax[1,1])
PanelD = sns.lineplot(data=Data[(Data['unit'] == 3) & (Data['year'] > 2002)], 
                      x ='year', y='y2', color='black', size=1, ax = ax[1,1])
PanelD = sns.scatterplot(data=Data[(Data['unit'] == 3) & (Data['year'] > 2002)], 
                         x ='year', y='y2', color='black', marker='s', 
                         ax = ax[1,1])
PanelD.axvline(2002, color = 'red', linestyle='dashed', linewidth=1)
PanelD.axvline(2005, color = 'red', linestyle='dashed', linewidth=1)
PanelD.set_yticks([0, 5, 10, 15, 20])
PanelD.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelD.legend([],[], frameon=False)
PanelD.set_ylabel('Outcome Variable')
PanelD.set_xlabel('Time')
PanelD.set_title('D. Early Group v/s Later Group After 2003')
```

As seen in the plots, in the decomposition with trends these effects are no longer constants of 3 and 2 for early and later treated units given that the "treatment effect" is no longer simply $1 \times unit$ in each case.

```{python}
# 2X2 DD Regressions
panelA = sm.OLS.from_formula('y2 ~ post + C(year) + C(unit)', 
                         data=Data[Data['unit'] != 2]).fit()
panelB = sm.OLS.from_formula('y2 ~ post + C(year) + C(unit)', 
                         data=Data[Data['unit'] != 3]).fit()
panelC = sm.OLS.from_formula('y2 ~ post + C(year) + C(unit)', 
                         data=Data[(Data['unit'] != 1) & (Data['year'] < 2006)]).fit()
panelD = sm.OLS.from_formula('y2 ~ post + C(year) + C(unit)', 
                         data=Data[(Data['unit'] != 1) & (Data['year'] > 2002)]).fit()
# 2x2 Betas
bkUk = panelA.params["post"]
bkUl = panelB.params["post"]
bklk = panelC.params["post"]
bkll = panelD.params["post"]
# Share of time treated
Dk = Data[Data['unit'] == 3]['post'].mean()
Dl = Data[Data['unit'] == 2]['post'].mean()
# How much treatment varies
VkU = 0.5*0.5*(Dk)*(1-Dk)
VlU = 0.5*0.5*(Dl)*(1-Dl) 
Vklk = 0.5*0.5*((Dk-Dl)/(1-Dl))*((1-Dk)/(1-Dl))
Vkll = 0.5*0.5*(Dl/Dk)*((Dk-Dl)/(Dk))
VD   = (sm.OLS.from_formula('post ~ C(unit) + C(year)', 
                           data=Data).fit().resid**2).mean()
# Share of sample
nk   = 1/3
nl   = 1/3
nu   = 1/3
# Weights
wkUk = (((nk + nu)**2)*VkU)/VD
wkUl = (((nl + nu)**2)*VlU)/VD
wklk = ((((nk + nl)*(1-Dl))**2)*Vklk)/VD
wkll = ((((nk + nl)*Dk)**2)*Vkll)/VD
# Tau
tau = bkUk*wkUk + bkUl*wkUl + bklk*wklk + bkll*wkll
print(tau)
```

What is noteworthy here is the surprising behaviour flagged by @GoodmanBacon2018 for the final comparison based on the case where the earlier treated unit (unit 3) is used as a control for the later trated unit (unit 2). In this case, given that there *are* time-varying treatment effects, despite the fact that each unit-specific treatment effect is positive, we observe that the parameter $\widehat{\beta}^{2 \times 2, l}_{kl}$ is actually *negative*. In this particular example this negative value (-1.375) is not sufficient to turn the weighted treatment effect estimate negative, but if you play around with the size of the parameters $\beta_1$ and $\beta_2$ above, you will see that large enough differences in trends *can* result in such estimates! Here, as above, we see that when we aggregate unit-specific estimates as `tau`, the estimate (by definition) agrees with the estimate generated by two-way fixed effect models previously.

### @deChaisemartinDhaultfoeuille2019's Procedure

Now, we will show that the procedures described in @deChaisemartinDhaultfoeuille2019, despite arriving to the estimator in a different way, also let us understand how the regression weights the two-way fixed effect estimator. In this case, rather than considering each treatment-control comparison pair, the authors note that the two-way fixed estimator can be conceived as a weighted sum of each single group by time period in any post-treatment group.

The authors define $\widehat{\beta}_{fe}$ as the coefficient estimated in the following (standard) two-way fixed effects regression: $$y_{i,s,t} = \beta_0 + \beta_{fe} D_{s,t} + \mu_s + \lambda_t + \varepsilon_{s,t}$$ Where $D_{s,t}$ is the mean over $i$ of a binary indicator variable that takes value of 1 if the unit $i$ in state $s$ is treated at period $t$ and 0 otherwise, in our case as we have one observartion per state $D_{s,t} = post_{s,t}$, meanwhile $\mu_s$ and $\lambda_t$ are state and time fixed effects. This is, of course, precisely the same model as we have estimated in @eq-twfe, implying that $\beta_{fe}=2.4545$ in cases without post-treatment trends (`y1`), or $\beta_{fe}=3.8045$ in cases with post-treatment dynamics (`y2`).

@deChaisemartinDhaultfoeuille2019 define the ATE for any ($s,t$) cell as: $$\Delta_{s,t} = \frac{1}{N_{s,t}} \sum_{i = 1}^{N_{s,t}}[Y_{i,s,t}(1) - Y_{i,s,t}(0)].$$  You will note that here we require an unobserved counterfactual $Y_{i,s,t}(0)$.  If we impose a parallel trend assumption, such a counterfactual can be inferred from unit-specific fixed effects, time-specific fixed effects, and the constant term.  Because in this case we *know* our data generating process, we can simply generate this counterfactual as the data generating process, absent any effect of treatment.  Below we generate such a counterfactual, where you will note that we impose that this is an 'untreated' counterfactual by setting the treatment effects to 0 in the generation of `y1_c` below:
```{python}
Data['y1_c'] = 2 + (Data['year'] - 2000) * 0.2 + 1 * Data['unit'] + 0 * Data['post'] * Data['unit'] + 0 * Data['post'] * Data['unit'] * (Data['time'])
```

It is likely useful to confirm to ourselves that graphically we are indeed generating the untreated counterfactual in this way.

```{python}
#| code-fold: true
#| code-summary: "Show the plot code"
[Fig4, ax] = plt.subplots(1,2)
### Unit 2
PanelA = sns.lineplot(data=Data[Data['unit'] == 2], x = 'year', y = 'y1',
                      color = 'blue', size = 1, ax = ax[0])
PanelA = sns.lineplot(data = Data[Data['unit'] == 2], x = 'year', y = 'y1_c',
                      color = 'red', size = 1, ax = ax[0], linestyle = 'dashed')
PanelA.legend([],[],frameon=False)
PanelA.set_yticks([4, 5, 6, 7, 8])
PanelA.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelA.set_ylabel("Y")
PanelA.set_xlabel("Year")
PanelA.set_title("(a) Unit 2 Outcome and Countefactual", y = -0.25)
### Unit 3
PanelB = sns.lineplot(data=Data[Data['unit'] == 3], x = 'year', y = 'y1',
                      color = 'blue', size = 1, ax = ax[1])
PanelB = sns.lineplot(data = Data[Data['unit'] == 3], x = 'year', y = 'y1_c',
                      color = 'red', size = 1, ax = ax[1], linestyle = 'dashed')
PanelB.legend([],[],frameon=False)
PanelB.set_yticks([5, 6, 7, 8, 9, 10])
PanelB.set_xticks([2000, 2002, 2004, 2006, 2008])
PanelB.set_ylabel("Y")
PanelB.set_xlabel("Year")
PanelB.set_title("(b) Unit 3 Outcome and Countefactual", y = -0.25)
```

This allows us to calculate a state- and time-period specific treatment effect ($\Delta_{s,t}$) for each treated unit.  We do so, calculating this quantity for all units in which treatment exists:

```{python}
Data['Delta_st'] = np.where(Data['post'] == 1, Data['y1'] - Data['y1_c'],
                            np.nan)
Data[Data['post'] == 1][['y1', 'y1_c', 'unit', 'year', 'Delta_st']]
```

Unsurprisingly, given the data generating process we have defined, we see that each treatment effect is 2 for unit 2, and 3 for unit 3. If we were to calculate a mean treatment effect by hand, we may wish to simply take an average over all periods and units.  However, one of the key results of @deChaisemartinDhaultfoeuille2019 is to show that under a series of standard assumptions $$\beta_{fe} = E \left[ \sum_{s,t:D_{s,t}=1}\frac{N_{s,t}}{N_1}w_{s,t}\Delta_{s,t} \right]$$ Where $N_1$ refers to the sum of all treated observations and $$w_{s,t} = \frac{\varepsilon_{s,t}}{\sum_{s,t:D_{s,t}=1}\frac{N_{s,t}}{N_1}\varepsilon_{s,t}}$$ Where $\varepsilon_{s,t}$ is the residual from a regression of $D_{s,t}$ on state and time fixed-effects.  To confirm this in our data, we will estimate these regression residuals and add them into the dataframe:

```{python}
auxreg = sm.OLS.from_formula('post ~ C(year) + C(unit)',
                             data=Data).fit()
Data['eps_st'] = auxreg.resid
Data['eps_st'] = np.where(Data['post'] != 1, np.nan, Data['eps_st'])
Data['w_st'] = Data['eps_st'] / Data['eps_st'].sum()
print(round(Data[Data['post'] == 1][['y1', 'y1_c', 'unit', 'year', 'Delta_st', 'w_st']], 6))
```
Note here that after generating $w_{s,t}$ we print this out using the round function to avoid very small digits appearing which are only different to zero given machine precision.  The key thing that we can see is that the effective weighting of treatment effects which occurs in regression is quite different to what we would expect.  Indeed, four periods are given 0 weights!  Finally, we can confirm that this decomposition gives us the two-way fixed effect estimate by multiplying $\Delta_{s,t}$ and $w_{s,t}$ and summing:


```{python}
print("de Chaisemartin and Xavier D'Haultfoeuille's decomposition returns an estimates of: " + str((Data['Delta_st'] * Data['w_st']).sum()))
```
We can see that correctly, this decomposition also returns the two-way fixed effect estimate of 2.4545.


We can follow precisely the same series of steps to see the case of the decomposition where treatment exposition also results in a trend-break.  To see this, we conduct each of the above steps below, however here we have not produced similar graphs (though you may wish to do so to confirm that counterfactuals make sense):

```{python}
Data['y2_c'] = 2 + (Data['year'] - 2000) * 0.2 + 1 * Data['unit'] + 0 * Data['post'] * Data['unit'] + 0 * Data['post'] * Data['unit'] * (Data['time'])
Data['Delta_st2'] = np.where(Data['post'] == 1, Data['y2'] - Data['y2_c'],
                            np.nan)
print(round(Data[Data['post'] == 1][['y2', 'y2_c', 'unit', 'year', 'Delta_st', 'w_st']], 6))
```

Because there is no difference in the structure of the treatment indicator or the unit and time fixed effects, the residuals $w_{s,t}$ are identical, though of course the treatment effects themselves, $\Delta_{s,t}$ are not.  Thus, once again we see that later treatment effects for unit 3 (precisely those units for which treatment effects are largest), are given zero weights.  Finally, again we can calculate the two-way fixed effect estimate following this decomposition by summing across units, capturing the estimate we have previously observed in regression models of 3.804545.  

```{python}
print("de Chaisemartin and Xavier D'Haultfoeuille's decomposition returns an estimates of: " + str((Data['Delta_st2'] * Data['w_st']).sum()))
```

Depending on the nature of treatment assignment, ie the number of treated periods, as well as the period in which treatment is adopted in different units, these weights will vary, and can even be negative.  You may wish to explore alternative set-ups and confirm to yourself that this is the case, and see that regardless of the nature of the setting, both @GoodmanBacon2018 and @deChaisemartinDhaultfoeuille2019's decompositions recover the two-way fixed effect estimate.

## Code call-out 4.3: Event study and Interaction-weighted Estimators


## Code call-out 4.4: Synthetic control, difference-in-differences, and synthetic difference-in-differences

The synthetic control method seeks to construct a "synthetic control" for a treated unit (in this case, California) using a weighted combination of control units (other states). The aim is for this synthetic control to closely resemble the treated unit in the pre-treatment period based on predictor variables.

-   Use the 'synth' command to construct the synthetic control for California
-   Predictor variables: cigsale from specific years, beer, lnincome, retprice, age15to24
-   Treated unit: California (state==3)
-   Treatment period: 1989
-   Periods used to construct the synthetic control: 1980-1988

Once the synthetic control is constructed, we can compare the trends of the treated unit and the synthetic control in the post-treatment period. Any divergence in trends is interpreted as the treatment effect. In this case, we are assessing the impact of a hypothetical policy implemented in California in 1989 on cigarette sales.

```{python eval=FALSE}

# import pandas as pd
# from SyntheticControlMethods import Synth
# 
# # Load the Dataset
# df = pd.read_stata("Datasets/smoking.dta")
# 
# # Prepare the Data
# df = df.sort_values(by=['state', 'year'])
# 
# # Define the treatment period and the unit receiving the treatment
# treatment_period = 1989
# treated_unit = 'California'
# 
# # Predictor variables - Ensure these are present in your dataset
# predictors = ['cigsale', 'beer', 'lnincome', 'retprice', 'age15to24']
# 
# # Fit the Synthetic Control Model
# sc = Synth(df, "cigsale", "state", "year", treatment_period, treated_unit, pen=0)
# 
# # Visualize the Synthetic Control
# sc.plot(["original", "pointwise", "cumulative"], treated_label="California", 
#         synth_label="Synthetic California", treatment_label="Tobacco Policy Change")


```

**Results:**

-   The synthetic control for California is constructed using a combination of other states. Specifically, weights are assigned to states like Colorado, Connecticut, Montana, Nevada, New Mexico, and Utah.
-   The RMSPE (Root Mean Squared Prediction Error) is a measure of how well the synthetic control approximates California in the pre-treatment period. A lower RMSPE indicates a better fit. In this case, the RMSPE is 1.756235, suggesting a reasonably good fit.
-   The "Predictor Balance" table shows how California and the synthetic control compare in terms of the predictor variables. The figures show that there is a good balance between the treated unit and the synthetic control on these variables.
-   The graph displays per capita cigarette sales in California and the synthetic control over time. The divergence between the two lines post-1989 represents the estimated effect of the policy
